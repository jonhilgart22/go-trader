{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b56636-6aec-4275-a855-237dd410abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm.keras import TqdmCallback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import RNNModel, TCNModel, TransformerModel, NBEATSModel, BlockRNNModel\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from darts.utils.likelihood_models import GaussianLikelihoodModel\n",
    "\n",
    "from darts.metrics import mape, mse\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "from darts.datasets import AirPassengersDataset, SunspotsDataset\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "from math import sqrt\n",
    "from time import time\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "from collections import defaultdict\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367072e3-2549-4e8c-aebe-27107874b56b",
   "metadata": {},
   "source": [
    "# The notebook leverages coinbase daily data\n",
    "- open, low, high, close, volume\n",
    "- unlike the other notebook where we have to create these daily candles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee17f4-acd1-4090-9575-c673abee5e2a",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098d87f4-f706-4a9d-b19c-7b63f1afdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df = pd.read_csv(\"../data/historic_crypto_prices - bitcoin_jan_2017_sep_4_2021.csv\", \n",
    "    index_col=0,\n",
    "    parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e7486c-5f45-49ca-9c07-4f340c59d9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>963.66</td>\n",
       "      <td>1003.08</td>\n",
       "      <td>958.70</td>\n",
       "      <td>998.33</td>\n",
       "      <td>1.477750e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>998.62</td>\n",
       "      <td>1031.39</td>\n",
       "      <td>996.70</td>\n",
       "      <td>1021.75</td>\n",
       "      <td>2.221850e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>1021.60</td>\n",
       "      <td>1044.08</td>\n",
       "      <td>1021.60</td>\n",
       "      <td>1043.84</td>\n",
       "      <td>1.851680e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>1044.40</td>\n",
       "      <td>1159.42</td>\n",
       "      <td>1044.40</td>\n",
       "      <td>1154.73</td>\n",
       "      <td>3.449460e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>1156.73</td>\n",
       "      <td>1191.10</td>\n",
       "      <td>910.42</td>\n",
       "      <td>1013.38</td>\n",
       "      <td>5.101990e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>47024.34</td>\n",
       "      <td>48189.55</td>\n",
       "      <td>46750.09</td>\n",
       "      <td>47166.69</td>\n",
       "      <td>3.473036e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>47099.77</td>\n",
       "      <td>49111.09</td>\n",
       "      <td>46562.44</td>\n",
       "      <td>48847.03</td>\n",
       "      <td>3.913940e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>48807.85</td>\n",
       "      <td>50343.42</td>\n",
       "      <td>48652.32</td>\n",
       "      <td>49327.72</td>\n",
       "      <td>3.950807e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>49288.25</td>\n",
       "      <td>50982.27</td>\n",
       "      <td>48386.09</td>\n",
       "      <td>50025.37</td>\n",
       "      <td>4.320618e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-04</th>\n",
       "      <td>50009.33</td>\n",
       "      <td>50545.58</td>\n",
       "      <td>49548.78</td>\n",
       "      <td>49944.63</td>\n",
       "      <td>3.747133e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1708 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close        volume\n",
       "date                                                            \n",
       "2017-01-01    963.66   1003.08    958.70    998.33  1.477750e+08\n",
       "2017-01-02    998.62   1031.39    996.70   1021.75  2.221850e+08\n",
       "2017-01-03   1021.60   1044.08   1021.60   1043.84  1.851680e+08\n",
       "2017-01-04   1044.40   1159.42   1044.40   1154.73  3.449460e+08\n",
       "2017-01-05   1156.73   1191.10    910.42   1013.38  5.101990e+08\n",
       "...              ...       ...       ...       ...           ...\n",
       "2021-08-31  47024.34  48189.55  46750.09  47166.69  3.473036e+10\n",
       "2021-09-01  47099.77  49111.09  46562.44  48847.03  3.913940e+10\n",
       "2021-09-02  48807.85  50343.42  48652.32  49327.72  3.950807e+10\n",
       "2021-09-03  49288.25  50982.27  48386.09  50025.37  4.320618e+10\n",
       "2021-09-04  50009.33  50545.58  49548.78  49944.63  3.747133e+10\n",
       "\n",
       "[1708 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89faec25-bb38-4d64-abee-6e7524b90d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ time, low, high, open, close, volume ]\n",
    "# 9/4\n",
    "# 49400, 50558.75, 50025, 49942.98, 7595.48816499],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf784fc0-1fd3-4afd-9d2e-ff72d42e4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "etherum_df = pd.read_csv(\"../data/historic_crypto_prices - etherum_jan_2017_sept_4_2021.csv\", \n",
    "    index_col=0,\n",
    "    parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3339a5a-274a-4c25-8b60-ffbe8fb9622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>3227.76</td>\n",
       "      <td>3466.99</td>\n",
       "      <td>3195.22</td>\n",
       "      <td>3433.73</td>\n",
       "      <td>2.728050e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>3430.76</td>\n",
       "      <td>3836.87</td>\n",
       "      <td>3387.41</td>\n",
       "      <td>3834.83</td>\n",
       "      <td>3.007089e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-02</th>\n",
       "      <td>3825.03</td>\n",
       "      <td>3830.71</td>\n",
       "      <td>3726.75</td>\n",
       "      <td>3790.99</td>\n",
       "      <td>2.438740e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-03</th>\n",
       "      <td>3787.49</td>\n",
       "      <td>4022.47</td>\n",
       "      <td>3712.68</td>\n",
       "      <td>3940.61</td>\n",
       "      <td>2.620777e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-04</th>\n",
       "      <td>3937.91</td>\n",
       "      <td>3969.45</td>\n",
       "      <td>3837.93</td>\n",
       "      <td>3887.83</td>\n",
       "      <td>2.080696e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close        volume\n",
       "date                                                        \n",
       "2021-08-31  3227.76  3466.99  3195.22  3433.73  2.728050e+10\n",
       "2021-09-01  3430.76  3836.87  3387.41  3834.83  3.007089e+10\n",
       "2021-09-02  3825.03  3830.71  3726.75  3790.99  2.438740e+10\n",
       "2021-09-03  3787.49  4022.47  3712.68  3940.61  2.620777e+10\n",
       "2021-09-04  3937.91  3969.45  3837.93  3887.83  2.080696e+10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etherum_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf902b6-b17f-469b-add1-c9d16c331096",
   "metadata": {},
   "source": [
    "### Create the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1fe545-55c7-4533-b893-8569688bc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BollingerBandsSimulator:\n",
    "\n",
    "    def __init__(self, df_original, from_date, period, \n",
    "                 window, no_of_std, ml_lookback_windows,  ml_prediction_n_days, model_name=\"TCN\", additional_dfs=[],\n",
    "                 stop_loss_pct=.10, figsize=None):\n",
    "        \"\"\"\n",
    "        df_original: The input dataframe containing candles we want to build bollinger bands from and predict.\n",
    "            Assumes thes date is the index\n",
    "        from_date: The start date to slice the df_original by\n",
    "        period: time frequency to build candles if needed and transform timeseries dataset\n",
    "        window: lookback window for bollinger bands + roling mean\n",
    "        no_of_std: number of std for bollinger bands\n",
    "        ml_lookback_windows: one lookback window per ML model\n",
    "        ml_prediction_n_days: n days in the future to predcit\n",
    "        additional_dfs: Additional DFs. Assumed to be the same dates are the df_original and have a 'close' col\n",
    "        stop_loss_pct: the percent under/over our short/buy to keep a stop at\n",
    "        \"\"\"\n",
    "        self.df = df_original\n",
    "        self.from_date = from_date\n",
    "        self.period = period\n",
    "        self.window = window\n",
    "        self.no_of_std = no_of_std\n",
    "        self.figsize = figsize\n",
    "        self.ml_lookback_windows = ml_lookback_windows\n",
    "        self.max_looback = max(ml_lookback_windows)\n",
    "        # vars for taking / exiting positions\n",
    "        self.ml_models_dict = {}\n",
    "        self.have_trained_ml_models = False\n",
    "        self.buy_entry_price = None\n",
    "        self.short_entry_price = None\n",
    "        self.ml_prediction_n_days = ml_prediction_n_days # the number of days in the future to predict\n",
    "        self.additional_dfs = additional_dfs\n",
    "        self.ml_train_cols = ['open', 'high', 'low', 'Rolling Mean', 'volume']\n",
    "        self.model_name = model_name # what type of ML model to train\n",
    "        self.pred_col = 'close'\n",
    "        self.stop_loss_price = 0 # Price at which we get out of our position\n",
    "        self.stop_loss_pct = .10 # percent to trail our buy/short until we get out\n",
    "        self.first_run = True # if first run, train the models longer\n",
    "        self.number_of_trades = 0\n",
    "        self.buy_has_crossed_mean = False\n",
    "        self.short_has_crossed_mean = False\n",
    "        self.ml_prediction_date_and_price = {}\n",
    "        self.mode = 'no_position' # the curent position we have\n",
    "        \n",
    "        self.start_time = time.time()\n",
    "        # trade analytics\n",
    "        self.position_entry_date = None\n",
    "        self.n_total_days_in_trades = 0\n",
    "        self.win_and_lose_amount_dict = {\n",
    "            'n_short_lost': 0,\n",
    "            'n_buy_lost': 0,\n",
    "            'n_short_won': 0,\n",
    "            'n_buy_won': 0,\n",
    "            '$_short_lost':0,\n",
    "            '$_buy_lost':0,\n",
    "            '$_short_won':0,\n",
    "            '$_buy_won':0\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def _scale_time_series_df_and_time_cols(self, input_df,  time_cols = ['year', 'month', 'day']):\n",
    "        ts_transformers = {}\n",
    "        ts_stacked_series = None\n",
    "        ts_transformers, ts_stacked_series = self._scale_time_series_df(input_df)\n",
    "            \n",
    "        \n",
    "        # build year and month and day series:\n",
    "        for col in time_cols:\n",
    "            transformer = Scaler()\n",
    "            transformed_series = transformer.fit_transform(datetime_attribute_timeseries(ts_stacked_series, attribute=col))\n",
    "            ts_transformers[col] = transformer    \n",
    "\n",
    "            ts_stacked_series = ts_stacked_series.stack(transformed_series)\n",
    "             \n",
    "\n",
    "        return ts_transformers, ts_stacked_series, TimeSeries.from_series(input_df[self.pred_col],  freq=self.period)\n",
    "    \n",
    "    def _scale_time_series_df(self, input_df, use_pred_col=False):\n",
    "        \"\"\"\n",
    "        Scale an input time series col from 0 to 1\n",
    "        \n",
    "        input_df: the DF that contains the col\n",
    "        use_pred_col: if we are transforming additional DFs, we can use the pred col 'close' for them\n",
    "        \"\"\"\n",
    "        ts_transformers = {}\n",
    "        ts_stacked_series = None\n",
    "        cols_to_transform = self.ml_train_cols.copy()\n",
    "        # if we have additional DFs, we can include their close price\n",
    "        if use_pred_col:\n",
    "            cols_to_transform.append(self.pred_col)\n",
    "        for col in cols_to_transform:\n",
    "            transformer = Scaler()\n",
    "\n",
    "            transformed_series = transformer.fit_transform(fill_missing_values(TimeSeries.from_series(input_df[col],\n",
    "                                                                                                      freq=self.period)))\n",
    "            ts_transformers[col] = transformer    \n",
    "\n",
    "            if ts_stacked_series:\n",
    "                ts_stacked_series = ts_stacked_series.stack(transformed_series)\n",
    "\n",
    "            else:\n",
    "                ts_stacked_series = transformed_series\n",
    "        return ts_transformers, ts_stacked_series\n",
    "    \n",
    "    def _add_additional_training_dfs(self, ts_stacked_series, additional_dfs, verbose = False):\n",
    "        \"\"\"\n",
    "        Scale any additional DFs provided (such as ETHER)\n",
    "        \n",
    "        ts_stacked_series: the current scaled lists from the df_original provided\n",
    "        additional_dfs: additional dataframes that have been sliced for the correct date\n",
    "        \"\"\"\n",
    "        all_ts_stacked_series = None\n",
    "        for df in additional_dfs:\n",
    "            additional_ts_transformers, additional_ts_stacked_series = self._scale_time_series_df(df, use_pred_col=True)\n",
    "            if all_ts_stacked_series is None:\n",
    "                if verbose:\n",
    "                    print('last date for training additional df data', additional_ts_stacked_series.time_index[-1])\n",
    "                all_ts_stacked_series = additional_ts_stacked_series\n",
    "            else:\n",
    "                return \"Error. More than one time series for _add_additional_training_dfs not implemented\"\n",
    "        return additional_ts_transformers, all_ts_stacked_series.stack(ts_stacked_series)\n",
    "    \n",
    "    def _check_ml_prediction(self, end_time,   tcn_first_epochs=200, tcn_sub_epochs=100, nbeats_first_epochs=10,\n",
    "                             nbeats_sub_epochs=2,\n",
    "                             verbose = False) -> float:\n",
    "        \"\"\"train ML model to predict price movement over the last self.ml_lookback_windows days \n",
    "            predicting over the next self.ml_prediction_n_days days in teh future\n",
    "        end_time: the current date to predict up to\n",
    "        output_chunk_length: number of predicts to make\n",
    "        tcn_first_epochs: n of training epochs for the first training run\n",
    "        tcn_sub_epochs: n of training epochs for subsequents training runs\n",
    "        nbeats_first_epochs: first epochs \n",
    "        nbeats_sub_epochs: epochs for NBEATS model\n",
    "        \"\"\"        \n",
    "        if not self.have_trained_ml_models: # create models once, retrain incrementally\n",
    "            print(\"Creating ML models\")\n",
    "                \n",
    "            for model_n in self.model_name:\n",
    "                for lookback_window in self.ml_lookback_windows:\n",
    "                    if model_n == \"NBEATS\":\n",
    "                        self.ml_models_dict[str(lookback_window)+\"_NBEATS\"] = NBEATSModel(input_chunk_length=lookback_window, \n",
    "                                                                      output_chunk_length=self.ml_prediction_n_days,\n",
    "                                                                       random_state=0,\n",
    "                                                                       model_name = str(lookback_window) + \"_nbeats\",\n",
    "                                                                       num_blocks=4,\n",
    "                                                                       layer_widths=256,\n",
    "                                                                      force_reset=True,\n",
    "                                                                            log_tensorboard=True)\n",
    "                    elif model_n == \"TCN\":\n",
    "                        self.ml_models_dict[str(lookback_window)+\"_TCN\"] = TCNModel(\n",
    "                            dropout=.1,\n",
    "                            random_state=0,\n",
    "                                dilation_base=2, \n",
    "                            weight_norm=True,\n",
    "                            kernel_size=3,\n",
    "                            num_filters=6,\n",
    "                            num_layers=6,\n",
    "                            input_chunk_length=lookback_window,\n",
    "                            output_chunk_length=self.ml_prediction_n_days,\n",
    "                        model_name = str(lookback_window) + \"_tcn\",\n",
    "                        force_reset=True,\n",
    "                        log_tensorboard=True)\n",
    "                    else:\n",
    "                        raise ValueError \n",
    "                        print(f\"Error. Incorrect input model of {self.model_name}\")  \n",
    "            self.have_trained_ml_models = True\n",
    "\n",
    "        training_df = self.df[self.df.index <= pd.to_datetime(end_time)]\n",
    "        # add in any additional DFs, like ETHER\n",
    "        additional_dfs_sliced = []\n",
    "        if len(self.additional_dfs) > 0:\n",
    "            for additional_df in self.additional_dfs:\n",
    "                additional_dfs_sliced.append(additional_df[additional_df.index <= pd.to_datetime(end_time)])\n",
    "        \n",
    "        # combine TS from both DFs\n",
    "        ts_transformers, ts_stacked_series, train_close_series = self._scale_time_series_df_and_time_cols(training_df)\n",
    "        if verbose:\n",
    "            print('original DF training series',         ts_stacked_series.components)\n",
    "            print('last date for training data', ts_stacked_series.time_index[-1])\n",
    "        \n",
    "\n",
    "        if len(self.additional_dfs) >0 :\n",
    "            # overwrite the ts_stacked_series var if we have additional DFS\n",
    "            additional_ts_transformers, ts_stacked_series =  self._add_additional_training_dfs(ts_stacked_series, additional_dfs_sliced)\n",
    "            # TODO: in the future, combine the ts_tra\n",
    "            ts_transformers = {**additional_ts_transformers, **ts_transformers} # merge dicts\n",
    "        \n",
    "        if verbose:\n",
    "            print('all series now stacked', ts_stacked_series.components)\n",
    "\n",
    "        # train the model & make predictions\n",
    "        all_predictions = []\n",
    "        for lookback_name, model in self.ml_models_dict.items():\n",
    "            if verbose:\n",
    "                print(f\"Lookback name = {lookback_name}, model = {model}\")\n",
    "                print(str(lookback_window)+\"_TCN\")\n",
    "                print(self.first_run, 'first run') \n",
    "            if self.first_run and \"TCN\" in lookback_name:\n",
    "                model.fit(series = train_close_series, past_covariates = [ts_stacked_series], \n",
    "                          verbose=verbose, epochs=tcn_first_epochs)\n",
    "            elif self.first_run and \"_NBEATS\" in lookback_name:\n",
    "                model.fit(series = train_close_series, past_covariates = [ts_stacked_series], \n",
    "                          verbose=verbose, epochs=nbeats_first_epochs)   \n",
    "            elif \"_NBEATS\" in lookback_name:\n",
    "                model.fit(series = train_close_series, past_covariates = [ts_stacked_series], \n",
    "                          verbose=verbose, epochs=nbeats_sub_epochs)                \n",
    "            elif \"_TCN\" in lookback_name:\n",
    "                model.fit(series = train_close_series, past_covariates = [ts_stacked_series], \n",
    "                          verbose=verbose, epochs=tcn_sub_epochs)\n",
    "            \n",
    "            ml_prediction = model.predict(n=self.ml_prediction_n_days, \n",
    "                    series=train_close_series, past_covariates = [ts_stacked_series]).last_value() # grab the last value\n",
    "            print(f\" Lookback = {lookback_name} Prediction = {ml_prediction}\")\n",
    "            all_predictions.append(ml_prediction)\n",
    "        self.first_run = False\n",
    "\n",
    "        \n",
    "        return np.mean(all_predictions) # average the predictions\n",
    "        \n",
    "\n",
    "    def _calculate_positions(self):\n",
    "        self.df['Position'] = None\n",
    "        self.df['Mode'] = None\n",
    "        self.df['ML_Future_Prediction']=None\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        for index in range(len(self.df)):\n",
    "            \n",
    "            row = self.df.iloc[index]\n",
    "            prev_row = self.df.iloc[index - 1]\n",
    "            \n",
    "            \n",
    "            if pd.to_datetime(row.name) < self.prediction_start: # lookback windows needed for ML model\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Mode')] =  self.mode\n",
    "                continue \n",
    "                    \n",
    "            if index == 0:\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Mode')] =  self.mode\n",
    "                continue\n",
    "            \n",
    "            # update stop loss\n",
    "            if self.mode == 'buy' and (1-self.stop_loss_pct)*row['close'] > self.stop_loss_price:\n",
    "                self.stop_loss_price = (1-self.stop_loss_pct)*row['close']\n",
    "                print(f\"Updating stop loss to {self.stop_loss_price}\")\n",
    "                print(row['close'], 'row close')\n",
    "            \n",
    "            if self.mode == 'short' and (1+self.stop_loss_pct)*row['close'] < self.stop_loss_price:\n",
    "                self.stop_loss_price = (1+self.stop_loss_pct)*row['close']\n",
    "                print(f\"Updating stop loss to {self.stop_loss_price}\")\n",
    "                print(row['close'], 'row close')\n",
    "\n",
    "                                                           \n",
    "            \n",
    "            # check if we've previously crossed the mean trailing price\n",
    "            if self.mode == 'buy'  and row['close'] > row['Rolling Mean']:\n",
    "                self.buy_has_crossed_mean = True\n",
    "                \n",
    "            if self.mode == 'short'  and row['close'] < row['Rolling Mean']:\n",
    "                self.short_has_crossed_mean = True\n",
    "            \n",
    "\n",
    "                \n",
    "            # stop loss, get out of buy position\n",
    "            if self.mode == 'buy' and self.stop_loss_price > row['close']:\n",
    "                print('----')\n",
    "                print('stop loss activated for getting out of our buy')\n",
    "                print(row.name, 'current date')\n",
    "                print(row['close'], 'row close')\n",
    "                print(self.stop_loss_price, 'self.stop_loss_price')\n",
    "                print(self.buy_entry_price, 'self.buy_entry_price')\n",
    "\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Position')] = 1\n",
    "                if index + 1  == len(self.df):\n",
    "                    self.df.iloc[index, self.df.columns.get_loc('Position')] = 0 \n",
    "                else:\n",
    "                    self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = 0 # for pct change it does a ffilll. ffill with zeros\n",
    "                self._determine_win_or_loss_amount(row)\n",
    "                # record keeping\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Mode')] = 'buy_to_no_position'\n",
    "                self.mode = 'no_position'\n",
    "                buy_has_crossed_mean = False\n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # stop loss, get out of short position\n",
    "            elif self.mode == 'short' and self.stop_loss_price  < row['close'] :\n",
    "                print('----')\n",
    "                print('stop loss activated for getting out of our short')\n",
    "                print(row.name, 'current date')\n",
    "                print(row['close'], 'row close')\n",
    "                print(self.stop_loss_price, 'self.stop_loss_price')\n",
    "                print(self.short_entry_price, 'self.short_entry_price')\n",
    "\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Position')] = -1\n",
    "                if index + 1  == len(self.df):\n",
    "                    self.df.iloc[index, self.df.columns.get_loc('Position')] = 0 \n",
    "                else:\n",
    "                    self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = 0 # for pct change it does a ffilll. ffill with zeros\n",
    "                self._determine_win_or_loss_amount(row)\n",
    "                # record keeping\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Mode')] = 'short_to_no_position'\n",
    "                self.mode = 'no_position'\n",
    "                short_has_crossed_mean = False\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # buy -> no_position? no position is below running mean\n",
    "            # or, if we are above the top band (mean reversion)\n",
    "            elif self.mode == 'buy'  and (\n",
    "                (row['close'] < row['Rolling Mean'] and self.buy_has_crossed_mean) or \n",
    "                (row['close'] > row['Bollinger High']) or \n",
    "                (row['close'] < row['Bollinger Low']) or \n",
    "                (row['Rolling Mean'] < self.buy_entry_price)):\n",
    "                self._check_buy_to_no_position(index, row)\n",
    "                    \n",
    "            \n",
    "            # short -> no_position? no position if above running mean\n",
    "            # or, if we are below the bottom band (mean reversion)\n",
    "            elif self.mode == 'short'  and (\n",
    "                (row['close'] > row['Rolling Mean'] and self.short_has_crossed_mean) or \n",
    "                (row['close'] < row['Bollinger Low']) or \n",
    "                (row['close'] > row['Bollinger High']) or\n",
    "                row['Rolling Mean'] > self.short_entry_price):\n",
    "                self._check_short_to_no_position(index, row)\n",
    "\n",
    "            # buy check with ML model\n",
    "            elif self.mode == 'no_position' and row['close'] < row['Bollinger Low'] and prev_row['close'] > prev_row['Bollinger Low']:\n",
    "                self._check_if_we_should_buy(index, row)\n",
    "\n",
    "            # short?\n",
    "            elif self.mode == 'no_position' and  row['close'] > row['Bollinger High'] and prev_row['close'] < prev_row['Bollinger High']:\n",
    "                self._check_if_we_should_short(index, row)\n",
    "        \n",
    "                       \n",
    "            else:\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "                \n",
    "                \n",
    "    def _determine_win_or_loss_amount(self, row):\n",
    "        \"\"\"\n",
    "        For position we've exited, did we win? if so, by how much\n",
    "        \"\"\"\n",
    "        # short s\n",
    "\n",
    "\n",
    "        if self.mode=='short' and self.short_entry_price  < row['close']: # stop loss for short\n",
    "            lost_amount = row['close'] - self.short_entry_price\n",
    "            print(f\"Lost {lost_amount} on this trade\")\n",
    "            \n",
    "            self.win_and_lose_amount_dict['n_short_lost'] += 1\n",
    "            self.win_and_lose_amount_dict['$_short_lost'] += lost_amount\n",
    "            \n",
    "\n",
    "        elif  self.mode == \"short\" and self.short_entry_price  > row['close']: # made money\n",
    "\n",
    "            win_amount = self.short_entry_price - row['close'] \n",
    "            print(f\"Won {win_amount} on this trade\")\n",
    "            self.win_and_lose_amount_dict['n_short_won'] += 1\n",
    "            self.win_and_lose_amount_dict['$_short_won'] += win_amount\n",
    "        # end short\n",
    "        # buys\n",
    "\n",
    "        elif  self.mode=='buy' and self.buy_entry_price  > row['close']: # lost money\n",
    "\n",
    "            lost_amount = self.buy_entry_price - row['close'] \n",
    "            print(f\"Lost {lost_amount} on this trade\")\n",
    "            self.win_and_lose_amount_dict['n_buy_lost'] += 1\n",
    "            self.win_and_lose_amount_dict['$_buy_lost'] += lost_amount\n",
    "\n",
    "        elif self.mode=='buy' and self.buy_entry_price  < row['close']: # made money\n",
    "\n",
    "            won_amount = row['close'] - self.buy_entry_price \n",
    "            print(f\"Won {won_amount} on this trade\")\n",
    "            self.win_and_lose_amount_dict['n_buy_won'] += 1\n",
    "            self.win_and_lose_amount_dict['$_buy_won'] += won_amount\n",
    "            \n",
    "        days_in_trade = row.name - self.position_entry_date\n",
    "        print(days_in_trade.days, \"days in trade\")\n",
    "        self.n_total_days_in_trades += days_in_trade.days\n",
    "        \n",
    "        ## info logging   \n",
    "        \n",
    "        print(f\"Average days in trades = {self.n_total_days_in_trades/(self.win_and_lose_amount_dict['n_buy_won']  + self.win_and_lose_amount_dict['n_buy_lost'] + self.win_and_lose_amount_dict['n_short_won']  + self.win_and_lose_amount_dict['n_short_lost'] )}\")\n",
    "        if self.win_and_lose_amount_dict['n_buy_won'] > 0 or self.win_and_lose_amount_dict['n_buy_lost'] > 0:\n",
    "            print(f\"Bat rate buy so far = {self.win_and_lose_amount_dict['n_buy_won'] / (self.win_and_lose_amount_dict['n_buy_won'] + self.win_and_lose_amount_dict['n_buy_lost'])}\")\n",
    "        if self.win_and_lose_amount_dict['n_short_won'] > 0 or self.win_and_lose_amount_dict['n_short_lost'] > 0:\n",
    "            print(f\"Bat rate short so far = {self.win_and_lose_amount_dict['n_short_won'] / (self.win_and_lose_amount_dict['n_short_won'] + self.win_and_lose_amount_dict['n_short_lost'])}\")\n",
    "                                       \n",
    "        if self.win_and_lose_amount_dict['$_buy_won'] > 0 or self.win_and_lose_amount_dict['$_buy_lost'] > 0:\n",
    "            print(f\"Win rate buy so far = {self.win_and_lose_amount_dict['$_buy_won'] / (self.win_and_lose_amount_dict['$_buy_won'] + self.win_and_lose_amount_dict['$_buy_lost'])}\")\n",
    "        if self.win_and_lose_amount_dict['$_short_won'] > 0 or self.win_and_lose_amount_dict['$_short_lost'] > 0:\n",
    "            print(f\"Win rate short so far = {self.win_and_lose_amount_dict['$_short_won'] / (self.win_and_lose_amount_dict['$_short_won'] + self.win_and_lose_amount_dict['$_short_lost'])}\")\n",
    "        print(f\"WIn / lost dict {self.win_and_lose_amount_dict}\")\n",
    "\n",
    "        \n",
    "        print(f\"Total days in trades = {self.n_total_days_in_trades }\")\n",
    "\n",
    "        \n",
    "        # reset for sanity\n",
    "        self.position_entry_date = None\n",
    "                \n",
    "                \n",
    "    def _check_short_to_no_position(self, index, row):\n",
    "        \"\"\"\n",
    "        While in a short position, check if we should exit\n",
    "        \"\"\"\n",
    "\n",
    "        print('---------')\n",
    "        print('checking if we should get out of our short position')\n",
    "        print(row.name, 'current date')\n",
    "        print(row['Rolling Mean'], 'mean')\n",
    "        print(self.short_entry_price, 'self.short_entry_price')\n",
    "        print(row['close'], 'current close')\n",
    "\n",
    "        # check ML predicted trend as well\n",
    "        try:\n",
    "            ml_pred = self._check_ml_prediction(row.name)\n",
    "        except ValueError: # don't have enough data for ML prediction\n",
    "            print('Ran into not enough data ValueError for short_to_no_position')\n",
    "            return\n",
    "        print(ml_pred, 'ml_pred')\n",
    "        if (ml_pred > row['Rolling Mean']) \\\n",
    "            or (ml_pred > self.short_entry_price) \\\n",
    "            or (row['Rolling Mean'] > self.short_entry_price):\n",
    "            print('short_to_no_position')\n",
    "            self.df['ML_Future_Prediction'] = ml_pred\n",
    "\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Position')] = -1\n",
    "            if index +1  == len(self.df):\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Position')] = 0 \n",
    "            else:\n",
    "                self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = 0 # for pct change it does a ffilll. ffill with zeros\n",
    "\n",
    "            self._determine_win_or_loss_amount(row)\n",
    "            # record keeping\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = 'short_to_no_position'\n",
    "            self.mode = 'no_position'\n",
    "            short_has_crossed_mean = False\n",
    "        else:\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "            \n",
    "    def _check_buy_to_no_position(self,  index, row):\n",
    "        \"\"\"\n",
    "        While in a buy/long position, check if we should exit\n",
    "        \"\"\"\n",
    "        print('---------')\n",
    "        print('checking if we should get out of our buy position')\n",
    "        print(row.name, 'current date')\n",
    "        print(row['Rolling Mean'], 'mean')\n",
    "        print(self.buy_entry_price, 'self.buy_entry_price')\n",
    "        print(row['close'], 'current close')\n",
    "\n",
    "\n",
    "        # check ML predicted trend as well\n",
    "        try:\n",
    "            ml_pred = self._check_ml_prediction(row.name)\n",
    "        except ValueError: # don't have enough data for ML prediction\n",
    "            print('Ran into not enough data ValueError for buy_to_no_position')\n",
    "            return\n",
    "        print(ml_pred, 'ml_pred')\n",
    "\n",
    "        if (ml_pred < row['Rolling Mean']) or \\\n",
    "             (ml_pred < self.buy_entry_price) or \\\n",
    "            (row['Rolling Mean'] < self.buy_entry_price):\n",
    "            print('buy_to_no_position')\n",
    "            self.df['ML_Future_Prediction'] = ml_pred\n",
    "\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Position')] = 1\n",
    "\n",
    "            if index + 1  == len(self.df):\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Position')] = 0 \n",
    "            else:\n",
    "                self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = 0 # for pct change it does a ffilll. ffill with zeros\n",
    "\n",
    "            self._determine_win_or_loss_amount(row)\n",
    "            # record keeping\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = 'buy_to_no_position'\n",
    "            self.mode = 'no_position'\n",
    "            self.buy_has_crossed_mean = False\n",
    "        else:\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "\n",
    "                \n",
    "    def _check_if_we_should_buy(self, index, row):\n",
    "        \"\"\"\n",
    "        Determine if we should enter a buy position\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        print('----------')\n",
    "        print('buy')\n",
    "        print(row.name, 'current date')\n",
    "        print(row['close'], 'close')\n",
    "        # check ML predicted trend as well\n",
    "        try:\n",
    "            ml_pred = self._check_ml_prediction(row.name)\n",
    "        except ValueError: # don't have enough data for ML prediction\n",
    "            print('Ran into not enough data ValueError for buy')\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "            return 9999999\n",
    "\n",
    "        print(ml_pred, 'ml prediction day')\n",
    "        print(row['Rolling Mean'], 'mean')\n",
    "\n",
    "        if ml_pred > row['Rolling Mean']:\n",
    "            print(f\"ml pred higher than mean taking position\")\n",
    "            self.df['ML_Future_Prediction'] = ml_pred\n",
    "            self.ml_prediction_date_and_price[row.name + timedelta(days=self.ml_prediction_n_days)] = ml_pred \n",
    "\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Position')] = 0 # buy. add one to index so that pct_change works\n",
    "\n",
    "            if index +1  == len(self.df):\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Position')] = 1 \n",
    "            else:\n",
    "                self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = 1 # buy. add one to index so that pct_change works\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = 'buy'\n",
    "            self.number_of_trades  +=1\n",
    "            self.mode = 'buy'    \n",
    "            self.buy_entry_price = row['close']\n",
    "            self.stop_loss_price = row['close']*(1-self.stop_loss_pct)\n",
    "            self.position_entry_date = row.name\n",
    "        else:\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Eval buy took {(end_time - start_time)/60} minutes\")\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    def _check_if_we_should_short(self, index, row):\n",
    "        \"\"\"\n",
    "        Check if we should enter a short position\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        print('----------')\n",
    "        print('short')\n",
    "        print(row.name, 'current date')\n",
    "        print(row['close'], 'close')\n",
    "        # check ML predicted trend as well\n",
    "        try:\n",
    "            ml_pred = self._check_ml_prediction(row.name)\n",
    "        except Exception as e: # don't have enough data for ML prediction\n",
    "            print('Ran into not enough data ValueError for short')\n",
    "            print(e)\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "            return 0\n",
    "\n",
    "        print(ml_pred, 'ml pred day')\n",
    "        print(row['Rolling Mean'], 'mean')\n",
    "\n",
    "        if ml_pred < row['Rolling Mean']:\n",
    "            print('pred 7 day lower than mean taking position')\n",
    "            self.df['ML_Future_Prediction'] = ml_pred\n",
    "            self.ml_prediction_date_and_price[row.name + timedelta(days=self.ml_prediction_n_days)] = ml_pred \n",
    "\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Position')] = 0 #  short starts at the end of the day. Calculate pct_change starting tomorrow\n",
    "            self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = -1 #  short starts at the end of the day. Calculate pct_change starting tomorrow\n",
    "            if index +1  == len(self.df):\n",
    "                self.df.iloc[index, self.df.columns.get_loc('Position')] = -1\n",
    "            else:\n",
    "                self.df.iloc[index + 1, self.df.columns.get_loc('Position')] = -1 # buy. add one to index so that pct_change works\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = 'short'\n",
    "            self.number_of_trades  += 1\n",
    "            self.mode = 'short' \n",
    "            self.short_entry_price = row['close']\n",
    "            self.stop_loss_price = row['close']*(1+self.stop_loss_pct)\n",
    "            self.position_entry_date = row.name\n",
    "        else:\n",
    "            self.df.iloc[index, self.df.columns.get_loc('Mode')] = self.mode\n",
    "            \n",
    "        end_time = time.time()\n",
    "        print(f\"Eval short took {(end_time - start_time)/60} minutes\")\n",
    "        \n",
    "                \n",
    "    def _build_bollinger_bands(self):\n",
    "        rolling_mean = self.df['close'].rolling(self.window).mean()\n",
    "        rolling_std = self.df['close'].rolling(self.window).std()\n",
    "\n",
    "        self.df['Rolling Mean'] = rolling_mean\n",
    "        self.df['Bollinger High'] = rolling_mean + (rolling_std * self.no_of_std)\n",
    "        self.df['Bollinger Low'] = rolling_mean - (rolling_std * self.no_of_std)\n",
    "        \n",
    "        new_additional_dfs = []\n",
    "        if len(self.additional_dfs) >0: \n",
    "            for df in self.additional_dfs:\n",
    "                rolling_mean = df['close'].rolling(self.window).mean()\n",
    "                rolling_std = df['close'].rolling(self.window).std()\n",
    "\n",
    "                df['Rolling Mean'] = rolling_mean\n",
    "                df['Bollinger High'] = rolling_mean + (rolling_std * self.no_of_std)\n",
    "                df['Bollinger Low'] = rolling_mean - (rolling_std * self.no_of_std)\n",
    "                \n",
    "                new_additional_dfs.append(df)\n",
    "        self.additional_dfs = new_additional_dfs\n",
    "        \n",
    "    def _calculate_returns(self):\n",
    "        \n",
    "        self.df['Original Position'] = self.df['Position']\n",
    "        self.df['Position'].fillna(method='ffill', inplace=True)\n",
    "        self.df['Market Return'] = self.df['close'].pct_change()\n",
    "        self.df['Strategy Return'] = self.df['Market Return'] * self.df['Position']\n",
    "\n",
    "    def _plot_returns(self):\n",
    "        self.df['Strategy Return'].cumsum().plot(figsize=self.figsize)\n",
    "    \n",
    "    def _slice_df(self):\n",
    "        self.df = self.df.loc[pd.to_datetime(self.from_date):, :].copy()\n",
    "        self.prediction_start = pd.to_datetime(self.from_date) + timedelta(self.max_looback)\n",
    "        \n",
    "        sliced_additional_dfs = []\n",
    "        if len(self.additional_dfs) > 0:\n",
    "            for add_df in self.additional_dfs:\n",
    "                sliced_df = add_df.loc[pd.to_datetime(self.from_date):, :].copy()\n",
    "                sliced_additional_dfs.append(sliced_df)\n",
    "\n",
    "        self.additional_dfs = sliced_additional_dfs\n",
    "        \n",
    "        \n",
    "\n",
    "    def simulate(self):\n",
    "        self._slice_df()\n",
    "        self._build_bollinger_bands()\n",
    "        self._calculate_positions()\n",
    "        self._calculate_returns()\n",
    "        self._plot_returns()\n",
    "        self.end_time = time.time()\n",
    "        \n",
    "        print(f\" Minutes taken = {(self.end_time - self.start_time)/60}\")\n",
    "\n",
    "        return (\n",
    "            self.period, \n",
    "            self.window, \n",
    "            self.no_of_std, \n",
    "            self.df['Strategy Return'].sum(),\n",
    "            self.number_of_trades\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37392d0-ce1c-43c1-916e-5dcd8aa940c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "buy\n",
      "2019-02-06 00:00:00 current date\n",
      "3413.77 close\n",
      "Creating ML models\n",
      "Ran into not enough data ValueError for buy\n",
      "----------\n",
      "short\n",
      "2019-02-08 00:00:00 current date\n",
      "3666.78 close\n",
      "Ran into not enough data ValueError for short\n",
      "__len__() should return >= 0\n",
      "----------\n",
      "short\n",
      "2019-02-18 00:00:00 current date\n",
      "3915.71 close\n",
      "Ran into not enough data ValueError for short\n",
      "__len__() should return >= 0\n",
      "----------\n",
      "buy\n",
      "2019-03-04 00:00:00 current date\n",
      "3761.56 close\n",
      " Lookback = 31_TCN Prediction = 4017.2699072331093\n",
      " Lookback = 31_NBEATS Prediction = 5102.017202490702\n",
      "4559.643554861906 ml prediction day\n",
      "3902.511428571429 mean\n",
      "ml pred higher than mean taking position\n",
      "Eval buy took 2.475540351867676 minutes\n",
      "Updating stop loss to 3506.742\n",
      "3896.38 row close\n",
      "Updating stop loss to 3513.5460000000003\n",
      "3903.94 row close\n",
      "Updating stop loss to 3520.332\n",
      "3911.48 row close\n",
      "Updating stop loss to 3566.979\n",
      "3963.31 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-03-09 00:00:00 current date\n",
      "3868.7364285714284 mean\n",
      "3761.56 self.buy_entry_price\n",
      "3963.31 current close\n",
      " Lookback = 31_TCN Prediction = 4162.733437658734\n",
      " Lookback = 31_NBEATS Prediction = 3890.192573729946\n",
      "4026.46300569434 ml_pred\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-03-10 00:00:00 current date\n",
      "3878.8199999999997 mean\n",
      "3761.56 self.buy_entry_price\n",
      "3951.6 current close\n",
      " Lookback = 31_TCN Prediction = 4152.23461737352\n",
      " Lookback = 31_NBEATS Prediction = 3386.8712238842722\n",
      "3769.5529206288966 ml_pred\n",
      "buy_to_no_position\n",
      "Won 190.03999999999996 on this trade\n",
      "6 days in trade\n",
      "Average days in trades = 6.0\n",
      "Bat rate buy so far = 1.0\n",
      "Win rate buy so far = 1.0\n",
      "WIn / lost dict {'n_short_lost': 0, 'n_buy_lost': 0, 'n_short_won': 0, 'n_buy_won': 1, '$_short_lost': 0, '$_buy_lost': 0, '$_short_won': 0, '$_buy_won': 190.03999999999996}\n",
      "Total days in trades = 6\n",
      "----------\n",
      "short\n",
      "2019-03-16 00:00:00 current date\n",
      "4048.73 close\n",
      " Lookback = 31_TCN Prediction = 4247.100081131182\n",
      " Lookback = 31_NBEATS Prediction = 3995.9267716704153\n",
      "4121.513426400799 ml pred day\n",
      "3913.6928571428575 mean\n",
      "Eval short took 0.6845938483874003 minutes\n",
      "----------\n",
      "short\n",
      "2019-03-27 00:00:00 current date\n",
      "4087.07 close\n",
      " Lookback = 31_TCN Prediction = 4320.0718450439035\n",
      " Lookback = 31_NBEATS Prediction = 4891.268951673671\n",
      "4605.670398358787 ml pred day\n",
      "4021.21 mean\n",
      "Eval short took 0.775376832485199 minutes\n",
      "----------\n",
      "short\n",
      "2019-03-29 00:00:00 current date\n",
      "4098.37 close\n",
      " Lookback = 31_TCN Prediction = 4308.975788786168\n",
      " Lookback = 31_NBEATS Prediction = 4472.617937168074\n",
      "4390.79686297712 ml pred day\n",
      "4041.367142857143 mean\n",
      "Eval short took 0.7480788032213846 minutes\n",
      "----------\n",
      "short\n",
      "2019-04-01 00:00:00 current date\n",
      "4158.18 close\n",
      " Lookback = 31_TCN Prediction = 4341.770997364006\n",
      " Lookback = 31_NBEATS Prediction = 3991.7840947611508\n",
      "4166.777546062578 ml pred day\n",
      "4060.2078571428574 mean\n",
      "Eval short took 0.7132821997006734 minutes\n",
      "----------\n",
      "short\n",
      "2019-04-18 00:00:00 current date\n",
      "5298.39 close\n",
      " Lookback = 31_TCN Prediction = 5747.9622232953325\n",
      " Lookback = 31_NBEATS Prediction = 6194.100404115089\n",
      "5971.031313705211 ml pred day\n",
      "5170.43 mean\n",
      "Eval short took 0.7053293148676555 minutes\n",
      "----------\n",
      "short\n",
      "2019-04-20 00:00:00 current date\n",
      "5337.89 close\n",
      " Lookback = 31_TCN Prediction = 5909.965935506871\n",
      " Lookback = 31_NBEATS Prediction = 5179.438606663805\n",
      "5544.702271085338 ml pred day\n",
      "5209.372857142857 mean\n",
      "Eval short took 0.7335093061129252 minutes\n",
      "----------\n",
      "short\n",
      "2019-04-22 00:00:00 current date\n",
      "5399.37 close\n",
      " Lookback = 31_TCN Prediction = 6053.221616352979\n",
      " Lookback = 31_NBEATS Prediction = 5961.033923381259\n",
      "6007.127769867119 ml pred day\n",
      "5225.460714285714 mean\n",
      "Eval short took 0.8954706986745199 minutes\n",
      "----------\n",
      "short\n",
      "2019-05-02 00:00:00 current date\n",
      "5505.28 close\n",
      " Lookback = 31_TCN Prediction = 6418.573305712128\n",
      " Lookback = 31_NBEATS Prediction = 6424.575423860338\n",
      "6421.574364786233 ml pred day\n",
      "5353.013571428572 mean\n",
      "Eval short took 0.789341950416565 minutes\n",
      "----------\n",
      "short\n",
      "2019-05-07 00:00:00 current date\n",
      "5829.5 close\n",
      " Lookback = 31_TCN Prediction = 6595.604538208526\n",
      " Lookback = 31_NBEATS Prediction = 7099.898664529599\n",
      "6847.751601369062 ml pred day\n",
      "5498.979285714287 mean\n",
      "Eval short took 0.8645252029101054 minutes\n",
      "----------\n",
      "short\n",
      "2019-05-19 00:00:00 current date\n",
      "8197.69 close\n",
      " Lookback = 31_TCN Prediction = 9681.817620674301\n",
      " Lookback = 31_NBEATS Prediction = 8654.339707316782\n",
      "9168.07866399554 ml pred day\n",
      "7071.536428571429 mean\n",
      "Eval short took 0.8565674821535746 minutes\n",
      "----------\n",
      "short\n",
      "2019-05-26 00:00:00 current date\n",
      "8673.22 close\n",
      " Lookback = 31_TCN Prediction = 10360.856645003085\n",
      " Lookback = 31_NBEATS Prediction = 9596.631286248617\n",
      "9978.74396562585 ml pred day\n",
      "7923.493571428572 mean\n",
      "Eval short took 0.8380362669626872 minutes\n",
      "----------\n",
      "buy\n",
      "2019-06-04 00:00:00 current date\n",
      "7707.77 close\n",
      " Lookback = 31_TCN Prediction = 10215.152872057268\n",
      " Lookback = 31_NBEATS Prediction = 10126.882588361565\n",
      "10171.017730209416 ml prediction day\n",
      "8326.999285714286 mean\n",
      "ml pred higher than mean taking position\n",
      "Eval buy took 0.8945387959480285 minutes\n",
      "Updating stop loss to 7041.807\n",
      "7824.23 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-05 00:00:00 current date\n",
      "8337.296428571428 mean\n",
      "7707.77 self.buy_entry_price\n",
      "7824.23 current close\n",
      " Lookback = 31_TCN Prediction = 10493.448627366042\n",
      " Lookback = 31_NBEATS Prediction = 10076.426581237103\n",
      "10284.937604301573 ml_pred\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-06 00:00:00 current date\n",
      "8333.022857142858 mean\n",
      "7707.77 self.buy_entry_price\n",
      "7822.02 current close\n",
      " Lookback = 31_TCN Prediction = 10161.996284358387\n",
      " Lookback = 31_NBEATS Prediction = 11596.894692483686\n",
      "10879.445488421035 ml_pred\n",
      "Updating stop loss to 7239.555\n",
      "8043.95 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-09 00:00:00 current date\n",
      "8259.667857142858 mean\n",
      "7707.77 self.buy_entry_price\n",
      "7688.08 current close\n",
      " Lookback = 31_TCN Prediction = 10311.85441650003\n",
      " Lookback = 31_NBEATS Prediction = 11868.212463394586\n",
      "11090.033439947307 ml_pred\n",
      "Updating stop loss to 7331.273999999999\n",
      "8145.86 row close\n",
      "Updating stop loss to 7407.828\n",
      "8230.92 row close\n",
      "Updating stop loss to 7824.447\n",
      "8693.83 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-14 00:00:00 current date\n",
      "8111.057142857143 mean\n",
      "7707.77 self.buy_entry_price\n",
      "8693.83 current close\n",
      " Lookback = 31_TCN Prediction = 10900.271183460982\n",
      " Lookback = 31_NBEATS Prediction = 10610.725245772564\n",
      "10755.498214616773 ml_pred\n",
      "Updating stop loss to 7954.5419999999995\n",
      "8838.38 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-15 00:00:00 current date\n",
      "8130.654285714286 mean\n",
      "7707.77 self.buy_entry_price\n",
      "8838.38 current close\n",
      " Lookback = 31_TCN Prediction = 11231.083252908898\n",
      " Lookback = 31_NBEATS Prediction = 9477.893917738946\n",
      "10354.488585323921 ml_pred\n",
      "Updating stop loss to 8095.041\n",
      "8994.49 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-16 00:00:00 current date\n",
      "8148.620714285715 mean\n",
      "7707.77 self.buy_entry_price\n",
      "8994.49 current close\n",
      " Lookback = 31_TCN Prediction = 11211.06373632396\n",
      " Lookback = 31_NBEATS Prediction = 9881.17262737433\n",
      "10546.118181849146 ml_pred\n",
      "Updating stop loss to 8388.315\n",
      "9320.35 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-17 00:00:00 current date\n",
      "8228.003571428571 mean\n",
      "7707.77 self.buy_entry_price\n",
      "9320.35 current close\n",
      " Lookback = 31_TCN Prediction = 11337.420890331457\n",
      " Lookback = 31_NBEATS Prediction = 9726.652866499187\n",
      "10532.036878415322 ml_pred\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-18 00:00:00 current date\n",
      "8326.145714285714 mean\n",
      "7707.77 self.buy_entry_price\n",
      "9081.76 current close\n",
      " Lookback = 31_TCN Prediction = 11270.11153304049\n",
      " Lookback = 31_NBEATS Prediction = 10466.001540852938\n",
      "10868.056536946715 ml_pred\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-19 00:00:00 current date\n",
      "8429.666428571429 mean\n",
      "7707.77 self.buy_entry_price\n",
      "9273.52 current close\n",
      " Lookback = 31_TCN Prediction = 11131.00833512865\n",
      " Lookback = 31_NBEATS Prediction = 11727.13576673757\n",
      "11429.072050933111 ml_pred\n",
      "Updating stop loss to 8574.444\n",
      "9527.16 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-20 00:00:00 current date\n",
      "8551.462142857143 mean\n",
      "7707.77 self.buy_entry_price\n",
      "9527.16 current close\n",
      " Lookback = 31_TCN Prediction = 11132.297042201326\n",
      " Lookback = 31_NBEATS Prediction = 12339.771292720841\n",
      "11736.034167461083 ml_pred\n",
      "Updating stop loss to 9130.104\n",
      "10144.56 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-21 00:00:00 current date\n",
      "8701.505714285715 mean\n",
      "7707.77 self.buy_entry_price\n",
      "10144.56 current close\n",
      " Lookback = 31_TCN Prediction = 11479.353125972606\n",
      " Lookback = 31_NBEATS Prediction = 13182.967031588953\n",
      "12331.16007878078 ml_pred\n",
      "Updating stop loss to 9631.521\n",
      "10701.69 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-22 00:00:00 current date\n",
      "8897.76 mean\n",
      "7707.77 self.buy_entry_price\n",
      "10701.69 current close\n",
      " Lookback = 31_TCN Prediction = 11932.314760608406\n",
      " Lookback = 31_NBEATS Prediction = 12798.446545372735\n",
      "12365.38065299057 ml_pred\n",
      "Updating stop loss to 9769.833\n",
      "10855.37 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-23 00:00:00 current date\n",
      "9123.994999999999 mean\n",
      "7707.77 self.buy_entry_price\n",
      "10855.37 current close\n",
      " Lookback = 31_TCN Prediction = 12128.347318910062\n",
      " Lookback = 31_NBEATS Prediction = 12222.297821669867\n",
      "12175.322570289965 ml_pred\n",
      "Updating stop loss to 9909.99\n",
      "11011.1 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-24 00:00:00 current date\n",
      "9339.050000000001 mean\n",
      "7707.77 self.buy_entry_price\n",
      "11011.1 current close\n",
      " Lookback = 31_TCN Prediction = 12350.938712234487\n",
      " Lookback = 31_NBEATS Prediction = 12094.092482330285\n",
      "12222.515597282385 ml_pred\n",
      "Updating stop loss to 10611.828\n",
      "11790.92 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-25 00:00:00 current date\n",
      "9614.993571428571 mean\n",
      "7707.77 self.buy_entry_price\n",
      "11790.92 current close\n",
      " Lookback = 31_TCN Prediction = 12880.533519573479\n",
      " Lookback = 31_NBEATS Prediction = 12641.70571224905\n",
      "12761.119615911264 ml_pred\n",
      "Updating stop loss to 11714.607\n",
      "13016.23 row close\n",
      "---------\n",
      "checking if we should get out of our buy position\n",
      "2019-06-26 00:00:00 current date\n",
      "9962.877142857144 mean\n",
      "7707.77 self.buy_entry_price\n",
      "13016.23 current close\n",
      " Lookback = 31_TCN Prediction = 14335.60854146667\n",
      " Lookback = 31_NBEATS Prediction = 13276.731440081576\n",
      "13806.169990774124 ml_pred\n",
      "----\n",
      "stop loss activated for getting out of our buy\n",
      "2019-06-27 00:00:00 current date\n",
      "11182.81 row close\n",
      "11714.607 self.stop_loss_price\n",
      "7707.77 self.buy_entry_price\n",
      "Won 3475.039999999999 on this trade\n",
      "23 days in trade\n",
      "Average days in trades = 14.5\n",
      "Bat rate buy so far = 1.0\n",
      "Win rate buy so far = 1.0\n",
      "WIn / lost dict {'n_short_lost': 0, 'n_buy_lost': 0, 'n_short_won': 0, 'n_buy_won': 2, '$_short_lost': 0, '$_buy_lost': 0, '$_short_won': 0, '$_buy_won': 3665.079999999999}\n",
      "Total days in trades = 29\n",
      "----------\n",
      "short\n",
      "2019-06-28 00:00:00 current date\n",
      "12407.33 close\n",
      " Lookback = 31_TCN Prediction = 13755.486979528414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "simulator = BollingerBandsSimulator(\n",
    "    bitcoin_df, \n",
    "    from_date=\"2019-1-01\", \n",
    "    period=\"24H\", \n",
    "    window=14, \n",
    "    no_of_std=1.25,\n",
    "    ml_lookback_windows=[31],\n",
    "    ml_prediction_n_days=30,\n",
    "    additional_dfs = [etherum_df],\n",
    "    stop_loss_pct=.10,\n",
    "    model_name=[\"TCN\", \"NBEATS\"]\n",
    ")\n",
    "simulator.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e2194-d295-49bf-983e-63cca20834a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aabcb0-a421-4181-b449-35291aef7585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2c504-5a0e-439a-a59c-4a1eabee3737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d89f7-d9ab-49c8-ad0d-003e0467bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99311b2-caf2-48c1-9859-4a3309136ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5050892e-da6b-45b9-b7bd-7c5117ef105e",
   "metadata": {},
   "source": [
    "#### Visualize Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71e29a-fa9c-4fcc-ad0e-63c5de5c65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FILTER = '2017-10-22'\n",
    "simulator.df[simulator.df.index > DATE_FILTER ]  [['Rolling Mean', 'Bollinger High', 'Bollinger Low', 'close']].plot(figsize=(19,8))\n",
    "\n",
    "prev_pos = None\n",
    "for index, pos in simulator.df[simulator.df.index > DATE_FILTER ]['Mode'].iteritems():\n",
    "    if pos == \"short\":\n",
    "        plt.axvline(index, color='red', linewidth=.3)\n",
    "    if pos == \"buy\":\n",
    "        plt.axvline(index, color='green', linewidth=.3)\n",
    "    if pos == 'short_to_no_position':\n",
    "        plt.axvline(index, color='black', linewidth=3)\n",
    "    if pos == 'buy_to_no_position':\n",
    "        plt.axvline(index, color='black', linewidth=3, label = 'buy_to_no_postiion')\n",
    "\n",
    "\n",
    "for key,val in simulator.ml_prediction_date_and_price.items():\n",
    "    plt.scatter(key, val, marker=\"*\", linewidths=4, color='brown', label='predictions')\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cf555-4f92-4621-84e7-ad20e776c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short\n",
    "# 2019-11-04 00:00:00 current date\n",
    "#  Lookback = 30 Prediction = 7337.89262836642\n",
    "#  Lookback = 90 Prediction = 9278.555809841882\n",
    "#  Lookback = 180 Prediction = 11221.047974868856\n",
    "# 9279.165471025719 ml prediction 7 day\n",
    "# 8554.994666666667 mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4987c-30a7-4517-90b6-ffc151eb6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.df[simulator.df.index > '2021-07-22' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0688bb9-7f18-47fb-bac2-86c1783401fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.df[simulator.df.index > '2021-08-31' ].Mode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb4af8-7d84-4218-8633-a65d530c69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(simulator.df.Mode == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9d4f1-ed47-4e68-af39-9073169495d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca4739-c109-482d-aaf8-0084dc3db585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a845f8-aa78-48c5-85b5-db4a1d161639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "go-trader",
   "language": "python",
   "name": "go-trader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
